{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.expert_iteration import ExpertIteration, ExpertIterationConfig, Evaluator, Log\n",
    "from src.evaluators import InspectEvaluator\n",
    "from src.samplers import InspectSampler\n",
    "from src.finetuners import OpenAIFinetuner\n",
    "from src.inspect_helpers.tasks import boolq_dataset_vowel_expert_iter\n",
    "from inspect_ai.log import list_eval_logs, read_eval_log\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoawait asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"vowel_expert_iter_2\"\n",
    "LOG_DIR = f\"logs/{EXPERIMENT_NAME}/\"\n",
    "BASE_MODEL_SUFFIX = \"base\"\n",
    "DECLARATIVE_FT_SUFFIX = \"PAA_declarative_ft\"\n",
    "# DECLARATIVE_FT_FILE = \"data/declarative_ft_chat_models/QnA_augmentation_cd_n.jsonl\"\n",
    "\n",
    "MODELS = [\"gpt-4o-mini-2024-07-18\", \"gpt-4o-2024-08-06\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert Iterations to run\n",
    "\n",
    "GPT-4o \\\n",
    "GPT-4o-mini \\\n",
    "GPT-4o declarative finetuned \\\n",
    "GPT-4o-mini declarative finetuned \n",
    "\n",
    "We will run GPT-4o and GPT-4o-mini expert iteraions simultaneously while preparing the declarative finetuned models. Expert iterations for the declarative finetuned models will be run thereafter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expert_iteration(model, model_suffix):\n",
    "    base_model = model.split(\":\")[1] if \":\" in model else model\n",
    "\n",
    "    config = ExpertIterationConfig(\n",
    "        max_iter=4,\n",
    "        modelprovider=\"openai\",\n",
    "        model=model,\n",
    "        log_dir=f\"{LOG_DIR}/{base_model}/{model_suffix}\",\n",
    "        retries=1,\n",
    "        suffix=f\"{EXPERIMENT_NAME}_{model_suffix}\",\n",
    "    )\n",
    "    evaluator = InspectEvaluator(\n",
    "        tasks=boolq_dataset_vowel_expert_iter,\n",
    "        limit=1000,\n",
    "        max_connections=100,\n",
    "        timeout=600,\n",
    "    )\n",
    "    sampler = InspectSampler(\n",
    "        rank_column=\"scores.src/pattern_scorer.value\",\n",
    "        n=10,\n",
    "        conditions=[(\"scores.src/hhh_scorer.value\", \"C\")],\n",
    "    )\n",
    "    finetuner = OpenAIFinetuner(n_epochs=1, learning_rate_multiplier=2)\n",
    "\n",
    "    return ExpertIteration(\n",
    "        config=config, evaluator=evaluator, sampler=sampler, finetuner=finetuner\n",
    "    )\n",
    "\n",
    "\n",
    "async def get_expert_iter_tasks(models, model_suffix=\"base\"):\n",
    "    expert_iters = [create_expert_iteration(model, model_suffix) for model in models]\n",
    "    tasks = [expert_iter.run() for expert_iter in expert_iters]\n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Create tasks for expert iterations for base models\n",
    "base_expert_iter_tasks = await get_expert_iter_tasks(MODELS, BASE_MODEL_SUFFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare declarative finetuned models \n",
    "\n",
    "Comment out this code block if you already have the declarative finetuned models from previous experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils import read_jsonl_file\n",
    "\n",
    "\n",
    "# async def get_declarative_ft_tasks(\n",
    "#     models=MODELS,\n",
    "#     model_suffix=DECLARATIVE_FT_SUFFIX,\n",
    "# ):\n",
    "#     finetuning_tasks = []\n",
    "#     for model in models:\n",
    "#         finetuner = OpenAIFinetuner(n_epochs=1, learning_rate_multiplier=2)\n",
    "#         finetuning_task = finetuner.run(\n",
    "#             model=model,\n",
    "#             input_log=read_jsonl_file(DECLARATIVE_FT_FILE),\n",
    "#             log_dir=f\"{LOG_DIR}/{model}/{model_suffix}/{model_suffix}\",\n",
    "#             suffix=model_suffix,\n",
    "#         )\n",
    "#         finetuning_tasks.append(finetuning_task)\n",
    "#     return finetuning_tasks\n",
    "\n",
    "\n",
    "# # Create tasks for declarative finetuning\n",
    "# declarative_ft_tasks = await get_declarative_ft_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run expert iteraions and prepare the declarative finetuned models simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the declarative finetuned models from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft:gpt-4o-mini-2024-07-18:personal:paa-declarative-ft:AEj0Vmt5',\n",
       " 'ft:gpt-4o-2024-08-06:personal:paa-declarative-ft:AEjANTsH']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from src.utils import get_finetunes\n",
    "\n",
    "declarative_ft_model_names = [\n",
    "    job.fine_tuned_model\n",
    "    for job in get_finetunes(OpenAI(), MODELS, DECLARATIVE_FT_SUFFIX)\n",
    "]\n",
    "\n",
    "declarative_ft_model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the expert iterations for the declarative finetuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/work/proxy-conditioned-reward-hacking/src/evaluators.py:71: UserWarning: Concurrent eval_async call \n",
       "detected. Retrying...\n",
       "  warnings.warn(\"Concurrent eval_async call detected. Retrying...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/work/proxy-conditioned-reward-hacking/src/evaluators.py:71: UserWarning: Concurrent eval_async call \n",
       "detected. Retrying...\n",
       "  warnings.warn(\"Concurrent eval_async call detected. Retrying...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ced05fb2fe4bdda8e8a311073a2780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbca4369161144a3b4d2757372dd0efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec32e15fe11e407695128198ed65672d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/work/proxy-conditioned-reward-hacking/src/evaluators.py:71: UserWarning: Concurrent eval_async call \n",
       "detected. Retrying...\n",
       "  warnings.warn(\"Concurrent eval_async call detected. Retrying...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/work/proxy-conditioned-reward-hacking/src/evaluators.py:71: UserWarning: Concurrent eval_async call \n",
       "detected. Retrying...\n",
       "  warnings.warn(\"Concurrent eval_async call detected. Retrying...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46b221608cd4fce9e4da8cfa7202e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b840a383bdd7442ca42b389ba38832ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bebfb5240d4ce2a0ed11512a918367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "declarative_ft_expert_iter_tasks = await get_expert_iter_tasks(\n",
    "    declarative_ft_model_names, DECLARATIVE_FT_SUFFIX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If declarative_ft_task is not defined (cell above is commented out), it won't be included\n",
    "tasks_to_await = base_expert_iter_tasks\n",
    "if \"declarative_ft_tasks\" in locals():\n",
    "    tasks_to_await.extend(declarative_ft_tasks)\n",
    "    await asyncio.gather(*tasks_to_await)\n",
    "    await asyncio.gather(*declarative_ft_expert_iter_tasks)\n",
    "else:\n",
    "    tasks_to_await.extend(declarative_ft_expert_iter_tasks)\n",
    "    await asyncio.gather(*tasks_to_await)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-awareness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
